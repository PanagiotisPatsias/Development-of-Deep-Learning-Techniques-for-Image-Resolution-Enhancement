{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def convert_rgb_to_y(img, dim_order='hwc'):\n",
    "    if dim_order == 'hwc':\n",
    "        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
    "    else:\n",
    "        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256. \n",
    "\n",
    "def denormalize(img):\n",
    "    img = img.mul(255.0).clamp(0.0, 255.0)\n",
    "    return img\n",
    "\n",
    "    \n",
    "def preprocess(img, device):\n",
    "    img = np.array(img).astype(np.float32)   \n",
    "    ycbcr = convert_rgb_to_ycbcr(img)\n",
    "    x = ycbcr[..., 0]\n",
    "    x /= 255.\n",
    "    x = torch.from_numpy(x).to(device)\n",
    "    x = x.unsqueeze(0).unsqueeze(0)\n",
    "    return x, ycbcr\n",
    "\n",
    "def calc_psnr(img1, img2, max=255.0):\n",
    "    return 10. * ((max ** 2) / ((img1 - img2) ** 2).mean()).log10()\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, h5_file, patch_size, scale):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.h5_file = h5_file\n",
    "        self.patch_size = patch_size\n",
    "        self.scale = scale\n",
    "\n",
    "    @staticmethod\n",
    "    def random_crop(lr, hr, size, scale):\n",
    "        lr_left = random.randint(0, lr.shape[1] - size)\n",
    "        lr_right = lr_left + size\n",
    "        lr_top = random.randint(0, lr.shape[0] - size)\n",
    "        lr_bottom = lr_top + size\n",
    "        hr_left = lr_left * scale\n",
    "        hr_right = lr_right * scale\n",
    "        hr_top = lr_top * scale\n",
    "        hr_bottom = lr_bottom * scale\n",
    "        lr = lr[lr_top:lr_bottom, lr_left:lr_right]\n",
    "        hr = hr[hr_top:hr_bottom, hr_left:hr_right]\n",
    "        return lr, hr\n",
    "\n",
    "    @staticmethod\n",
    "    def random_horizontal_flip(lr, hr):\n",
    "        if random.random() < 0.5:\n",
    "            lr = lr[:, ::-1, :].copy()\n",
    "            hr = hr[:, ::-1, :].copy()\n",
    "        return lr, hr\n",
    "\n",
    "    @staticmethod\n",
    "    def random_vertical_flip(lr, hr):\n",
    "        if random.random() < 0.5:\n",
    "            lr = lr[::-1, :, :].copy()\n",
    "            hr = hr[::-1, :, :].copy()\n",
    "        return lr, hr\n",
    "\n",
    "    @staticmethod\n",
    "    def random_rotate_90(lr, hr):\n",
    "        if random.random() < 0.5:\n",
    "            lr = np.rot90(lr, axes=(1, 0)).copy()\n",
    "            hr = np.rot90(hr, axes=(1, 0)).copy()\n",
    "        return lr, hr\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            lr = f['lr'][str(idx)][::]\n",
    "            hr = f['hr'][str(idx)][::]\n",
    "            lr, hr = self.random_crop(lr, hr, self.patch_size, self.scale)\n",
    "            lr, hr = self.random_horizontal_flip(lr, hr)\n",
    "            lr, hr = self.random_vertical_flip(lr, hr)\n",
    "            lr, hr = self.random_rotate_90(lr, hr)\n",
    "            lr = lr.astype(np.float32).transpose([2, 0, 1]) / 255.0\n",
    "            hr = hr.astype(np.float32).transpose([2, 0, 1]) / 255.0\n",
    "            return lr, hr\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])\n",
    "\n",
    "\n",
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        super(EvalDataset, self).__init__()\n",
    "        self.h5_file = h5_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            lr = f['lr'][str(idx)][::].astype(np.float32).transpose([2, 0, 1]) / 255.0\n",
    "            hr = f['hr'][str(idx)][::].astype(np.float32).transpose([2, 0, 1]) / 255.0\n",
    "            return lr, hr\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([x, self.relu(self.conv(x))], 1)\n",
    "\n",
    "\n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(RDB, self).__init__()\n",
    "        self.layers = nn.Sequential(*[DenseLayer(in_channels + growth_rate * i, growth_rate) for i in range(num_layers)])\n",
    "\n",
    "        # local feature fusion\n",
    "        self.lff = nn.Conv2d(in_channels + growth_rate * num_layers, growth_rate, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.lff(self.layers(x))  # local residual learning\n",
    "\n",
    "\n",
    "class RDN(nn.Module):\n",
    "    def __init__(self, scale_factor, num_channels, num_features, growth_rate, num_blocks, num_layers):\n",
    "        super(RDN, self).__init__()\n",
    "        self.G0 = num_features\n",
    "        self.G = growth_rate\n",
    "        self.D = num_blocks\n",
    "        self.C = num_layers\n",
    "\n",
    "        # shallow feature extraction\n",
    "        self.sfe1 = nn.Conv2d(num_channels, num_features, kernel_size=3, padding=3 // 2)\n",
    "        self.sfe2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=3 // 2)\n",
    "\n",
    "        # residual dense blocks\n",
    "        self.rdbs = nn.ModuleList([RDB(self.G0, self.G, self.C)])\n",
    "        for _ in range(self.D - 1):\n",
    "            self.rdbs.append(RDB(self.G, self.G, self.C))\n",
    "\n",
    "        # global feature fusion\n",
    "        self.gff = nn.Sequential(\n",
    "            nn.Conv2d(self.G * self.D, self.G0, kernel_size=1),\n",
    "            nn.Conv2d(self.G0, self.G0, kernel_size=3, padding=3 // 2)\n",
    "        )\n",
    "\n",
    "        # up-sampling\n",
    "        assert 2 <= scale_factor <= 4\n",
    "        if scale_factor == 2 or scale_factor == 4:\n",
    "            self.upscale = []\n",
    "            for _ in range(scale_factor // 2):\n",
    "                self.upscale.extend([nn.Conv2d(self.G0, self.G0 * (2 ** 2), kernel_size=3, padding=3 // 2),\n",
    "                                     nn.PixelShuffle(2)])\n",
    "            self.upscale = nn.Sequential(*self.upscale)\n",
    "        else:\n",
    "            self.upscale = nn.Sequential(\n",
    "                nn.Conv2d(self.G0, self.G0 * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n",
    "                nn.PixelShuffle(scale_factor)\n",
    "            )\n",
    "\n",
    "        self.output = nn.Conv2d(self.G0, num_channels, kernel_size=3, padding=3 // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sfe1 = self.sfe1(x)\n",
    "        sfe2 = self.sfe2(sfe1)\n",
    "\n",
    "        x = sfe2\n",
    "        local_features = []\n",
    "        for i in range(self.D):\n",
    "            x = self.rdbs[i](x)\n",
    "            local_features.append(x)\n",
    "\n",
    "        x = self.gff(torch.cat(local_features, 1)) + sfe1  # global residual learning\n",
    "        x = self.upscale(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "train_file = '../input/div2k-x3/DIV2K_x3.h5'\n",
    "eval_file = '../input/setx3/Set5_x3 (1).h5'\n",
    "outputs_dir = 'outputs'\n",
    "#weight_file = ''\n",
    "num_features = 64\n",
    "growth_rate = 64\n",
    "num_blocks = 16\n",
    "num_layers = 8\n",
    "scale = 3\n",
    "patch_size = 32\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 200\n",
    "num_workers = 8\n",
    "seed = 123\n",
    "\n",
    "\n",
    "\n",
    "outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n",
    "\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = RDN(scale_factor=scale,\n",
    "            num_channels=3,\n",
    "            num_features=num_features,\n",
    "            growth_rate=growth_rate,\n",
    "            num_blocks=num_blocks,\n",
    "            num_layers=num_layers).to(device)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_dataset = TrainDataset(train_file, patch_size=patch_size, scale=scale)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True)\n",
    "eval_dataset = EvalDataset(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] =lr * (0.1 ** (epoch // int(num_epochs * 0.8)))\n",
    "\n",
    "    model.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size), ncols=80) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "    ssim_score = AverageMeter()\n",
    "    \n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs)\n",
    "\n",
    "        preds = convert_rgb_to_y(denormalize(preds.squeeze(0)), dim_order='chw')\n",
    "        labels = convert_rgb_to_y(denormalize(labels.squeeze(0)), dim_order='chw')\n",
    "\n",
    "        preds = preds[scale:-scale, scale:-scale]\n",
    "        labels = labels[scale:-scale, scale:-scale]\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "        x1 = preds.cpu().squeeze(0).squeeze(0).numpy()/255.\n",
    "        x2 = labels.cpu().squeeze(0).squeeze(0).numpy()/255.\n",
    "        ssim_score.update(ssim(x1,x2,data_range = 1.0,win_size=3), len(inputs))\n",
    "    print('SSIM: {:.4f}'.format(ssim_score.avg))\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import PIL.Image as pil_image\n",
    "\n",
    "\n",
    "weights_file = './outputs/x3/best.pth'\n",
    "image_file = '../input/119082/119082.png'\n",
    "num_features = 64\n",
    "growth_rate = 64\n",
    "num_blocks = 16\n",
    "num_layers = 8\n",
    "scale = 3\n",
    "\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = RDN(scale_factor=scale,\n",
    "            num_channels=3,\n",
    "            num_features=num_features,\n",
    "            growth_rate=growth_rate,\n",
    "            num_blocks=num_blocks,\n",
    "            num_layers=num_layers).to(device)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n",
    "    if n in state_dict.keys():\n",
    "        state_dict[n].copy_(p)\n",
    "    else:\n",
    "        raise KeyError(n)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "image = pil_image.open(image_file).convert('RGB')\n",
    "\n",
    "image_width = (image.width // scale) * scale\n",
    "image_height = (image.height // scale) * scale\n",
    "\n",
    "hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n",
    "bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n",
    "\n",
    "lr = np.expand_dims(np.array(lr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n",
    "hr = np.expand_dims(np.array(hr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n",
    "lr = torch.from_numpy(lr).to(device)\n",
    "hr = torch.from_numpy(hr).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(lr).squeeze(0)\n",
    "\n",
    "preds_y = convert_rgb_to_y(denormalize(preds), dim_order='chw')\n",
    "hr_y = convert_rgb_to_y(denormalize(hr.squeeze(0)), dim_order='chw')\n",
    "\n",
    "preds_y = preds_y[scale:-scale, scale:-scale]\n",
    "hr_y = hr_y[scale:-scale, scale:-scale]\n",
    "\n",
    "psnr = calc_psnr(hr_y, preds_y)\n",
    "print('PSNR: {:.6f}'.format(psnr))\n",
    "\n",
    "\n",
    "\n",
    "x1 = hr_y.squeeze(0).squeeze(0).cpu().numpy()/255.\n",
    "x2 = preds_y.squeeze(0).squeeze(0).cpu().numpy()/255.\n",
    "ssim_score = ssim(x1,x2,data_range = 1.0,win_size=3)\n",
    "print('SSIM: {:.6f}'.format(ssim_score))\n",
    "\n",
    "output = pil_image.fromarray(denormalize(preds).permute(1, 2, 0).byte().cpu().numpy())\n",
    "hr =  pil_image.fromarray(denormalize(preds).permute(1, 2, 0).byte().cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize = (50,50))\n",
    "\n",
    "plt.subplot(231)\n",
    "\n",
    "plt.imshow(output)\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(hr)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
